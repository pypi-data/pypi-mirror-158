{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# script to convert *.las files to potree 1.6 compatible octrees using laspy and numpy.\n",
    "# A great source for *laz files is http://3dsm.bk.tudelft.nl/matahn \n",
    "#\n",
    "# Code is setup to enable parallel processing\n",
    "# TODO: optimize code\n",
    "# TODO: allow multicore processing\n",
    "# TODO: allow more paramaters than just x,y,z to be parsed\n",
    "# TODO: change code to module\n",
    "# TODO: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import laspy \n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import json\n",
    "from pathlib import Path\n",
    "import copy\n",
    "from contexttimer import Timer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert laz to las using las2las\n",
    "LAS_DIRECTORY = 'E:\\pointclouds'\n",
    "p = Path(LAS_DIRECTORY)\n",
    "for f in p.glob('*.laz'):\n",
    "    fn = f.__str__()\n",
    "    fn_new = fn.replace('.laz', '.las')\n",
    "    if not os.path.exists(fn_new):\n",
    "        cmd = r'\"C:\\Program Files (x86)\\lastools\\bin\\las2las.exe\" -i {} -o {} '.format(fn,fn_new)\n",
    "        os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make a generator for file headers\n",
    "# http://pythonhosted.org/laspy/header.html\n",
    "p = Path(LAS_DIRECTORY)\n",
    "def headers():\n",
    "    for f in p.glob('*.las'):\n",
    "        fn = f.__str__()\n",
    "        lasfile = laspy.file.File(fn)\n",
    "        yield lasfile.header    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  9.25141500e+04   4.38354630e+05   1.61280000e+02]\n",
      " [  9.13902400e+04   4.37388640e+05  -1.98100000e+01]]\n",
      "[0.01, 0.01, 0.01]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds = np.array((\n",
    "    np.max([hdr.max for hdr in headers()],axis=0),\n",
    "    np.min([hdr.min for hdr in headers()],axis=0),\n",
    "    ))\n",
    "print(bounds)\n",
    "[print(hdr.scale) for hdr in headers()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1123.91\n",
      "4.0 [ 91952 437871     70]\n"
     ]
    }
   ],
   "source": [
    "# define maximum bounding cube for data. MUST be cube, so all sides equal length\n",
    "min_size = max(bounds[0,:] - bounds[1,:])\n",
    "print(min_size)\n",
    "suggested_centers = ((bounds[0,:] + bounds[1,:])/2).astype(np.dtype('<i4'))\n",
    "suggested_levels = np.ceil(np.log2(min_size/100))\n",
    "print(suggested_levels,suggested_centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'y': array([351644, 454044]), 'x': array([ 74660, 177060]), 'z': array([-51250,  51150])}\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "CENTERS = {'x': 125860, 'y':402844, 'z':-50}\n",
    "SMALLEST_TILE_SIZE = 25 # meter\n",
    "LEVELS = 12\n",
    "SCALE = 0.01\n",
    "OUTPUT_DIR = Path(r'D:\\pointclouds\\potree\\data')\n",
    "# define size as nice power of two (not necessary)\n",
    "SIZE = SMALLEST_TILE_SIZE * 2 ** LEVELS\n",
    "BBOX = {k: np.array([v-SIZE/2, v+SIZE/2]).astype('i4') for k, v in CENTERS.items()}\n",
    "\n",
    "print(BBOX)\n",
    "# check if all points are within bounding box\n",
    "print([[h_min>=BBOX[dim][0] and h_max<=BBOX[dim][1] for\n",
    "       dim, h_min, h_max in zip(['x','y','z'],\n",
    "                                hdr.min,\n",
    "                                hdr.max)] for\n",
    "       hdr in headers()])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\pointclouds\\potree\\data\\r\\r000.bin\n",
      "D:\\pointclouds\\potree\\data\\r\\11231\\r112312312.bin\n",
      "D:\\pointclouds\\potree\\data\\r\\r7000.bin\n",
      "D:\\pointclouds\\potree\\data\\r\\r.bin\n"
     ]
    }
   ],
   "source": [
    "HIERACHY_STEP_SIZE = 5\n",
    "def address_to_path(address):\n",
    "    if address is '':\n",
    "        return Path(OUTPUT_DIR,'r','r.bin')\n",
    "\n",
    "    parts = [address[i:i+HIERACHY_STEP_SIZE] for i in range(0, len(address)+1, HIERACHY_STEP_SIZE)]\n",
    "    parts[-1]='r' + address + '.bin'\n",
    "    return Path(OUTPUT_DIR,'r',*parts)\n",
    "\n",
    "print(address_to_path('000'))\n",
    "print(address_to_path('112312312'))  \n",
    "print(address_to_path('7000'))\n",
    "print(address_to_path(''))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0\n",
      "0 2180000 8760000\n",
      "5120000 5120000 5120000\n",
      "0 0 0\n"
     ]
    }
   ],
   "source": [
    "def address_2_origin(address):\n",
    "    \"\"\" Each tile is saved in coordinates relitive to the origin of the tile.\n",
    "    The origin of a file can be calculated from the bounding box (BBOX) and the address\n",
    "    \"\"\"\n",
    "    if address == '':\n",
    "        address = '0'\n",
    "\n",
    "    # return origin relative to bounding box origin in unscaled values\n",
    "    level = len(address)\n",
    "    bin_parts = [bin(int(c)+8)[3::] for c in address]\n",
    "    x0 = int((int(''.join([b[0] for b in bin_parts]),2) / 2**level) * SIZE / SCALE)\n",
    "    y0 = int((int(''.join([b[1] for b in bin_parts]),2) / 2**level) * SIZE / SCALE)\n",
    "    z0 = int((int(''.join([b[2] for b in bin_parts]),2) / 2**level) * SIZE / SCALE)\n",
    "    return (x0, y0, z0)\n",
    "\n",
    "print(*address_2_origin('000'))\n",
    "print(*address_2_origin('112312312'))  \n",
    "print(*address_2_origin('7000'))\n",
    "print(*address_2_origin(''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed 0 files at level 0\n",
      "removed 0 files at level 1\n",
      "removed 0 files at level 2\n",
      "removed 0 files at level 3\n",
      "removed 0 files at level 4\n",
      "removed 0 files at level 5\n",
      "removed 0 files at level 6\n",
      "removed 0 files at level 7\n",
      "removed 0 files at level 8\n",
      "removed 0 files at level 9\n",
      "removed 0 files at level 10\n",
      "removed 0 files at level 11\n"
     ]
    }
   ],
   "source": [
    "p = Path(OUTPUT_DIR,'r')\n",
    "for n in range(0,LEVELS):\n",
    "    print('removed',len([f.unlink() for f in p.rglob('r'+ ('?' * n) + '.bin')]),'files at level', n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_chunk(data,bins,hdr):\n",
    "    # put all points in bins\n",
    "    # Simple was: \n",
    "    #    binned = np.vstack((np.digitize(d, b) for d, b in zip(data,bins)))\n",
    "    # optimiziation: \n",
    "    #    remove bins smaller than min in data before digitize, is huge speed improvement\n",
    "    binned = np.vstack(\n",
    "        (np.digitize(d, np.extract(b>=d.min(),b)) + np.where(b>=d.min())[0][0]\n",
    "         for d, b in zip(data,bins)))\n",
    "\n",
    "    for x in np.unique(binned[0]):\n",
    "        ix = np.equal(binned[0],x)\n",
    "        data_x = data[:,ix]\n",
    "        binned_x = binned[:,ix]\n",
    "        address_x = bin(x + 2**LEVELS)[-LEVELS::]\n",
    "\n",
    "        for y in np.unique(binned_x[1]):\n",
    "            iy = np.equal(binned_x[1],y)\n",
    "            data_xy = data_x[:,iy]\n",
    "            binned_xy = binned_x[:,iy]\n",
    "            address_y = bin(y + 2**LEVELS)[-LEVELS::]\n",
    "            \n",
    "            for z in np.unique(binned_xy[2]):\n",
    "                iz = np.equal(binned_xy[2],z)\n",
    "                data_xyz = data_xy[:,iz]\n",
    "                address_z = bin(z + 2**LEVELS)[-LEVELS::]\n",
    "                \n",
    "                # make filename of 0-7's\n",
    "                # https://github.com/potree/potree/blob/master/docs/file_format.md\n",
    "                address = ''.join([str(int(''.join((x,y,z)),2)) for x,y,z in zip(address_x,address_y,address_z)])\n",
    "                \n",
    "                filename = address_to_path(address).__str__()\n",
    "\n",
    "                # convert points from int32 relative to hdr.scale and hdr.offset to uint32 relative to SCALE, BBOX\n",
    "                # and the tile box address\n",
    "                x0, y0, z0 = address_2_origin(address)\n",
    "\n",
    "                if not os.path.exists(os.path.dirname(filename)):\n",
    "                    os.makedirs(os.path.dirname(filename))\n",
    "                with open(filename,'a') as f:\n",
    "                    np.vstack((\n",
    "                         (((data_xyz[0] * hdr.scale[0]) + hdr.offset[0] - BBOX['x'][0]) / SCALE).astype('<u4') - x0,\n",
    "                         (((data_xyz[1] * hdr.scale[1]) + hdr.offset[1] - BBOX['y'][0]) / SCALE).astype('<u4') - y0,\n",
    "                         (((data_xyz[2] * hdr.scale[2]) + hdr.offset[2] - BBOX['z'][0]) / SCALE).astype('<u4') - z0\n",
    "                         )).transpose().tofile(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_file(fn, t, processed):\n",
    "\n",
    "    with laspy.file.File(fn) as lasfile:\n",
    "        hdr = lasfile.header\n",
    "        # check if all points are within bounding box\n",
    "        print([h_min>=BBOX[dim][0] and h_max<=BBOX[dim][1] for\n",
    "               dim, h_min, h_max in zip(['x','y','z'],\n",
    "                                        hdr.min,\n",
    "                                        hdr.max)])\n",
    "\n",
    "        # to avoid duplicating the point coordinates in memory, discretize the points based on their raw coordinates\n",
    "        # in unscaled integers\n",
    "        bbox_unscaled = {dim: ((BBOX[dim]-offset)/scale).astype('i4') for \n",
    "                       dim, scale, offset in zip(['x','y','z'], hdr.scale, hdr.offset)}\n",
    "\n",
    "\n",
    "        # determine the bins to classify points\n",
    "        bins = tuple(np.linspace(bbox_unscaled[dim][0],\n",
    "                            bbox_unscaled[dim][1],\n",
    "                            2**(LEVELS)+1\n",
    "                           ).astype('i4')[1:-1] for dim in ['x','y','z'])\n",
    "\n",
    "        for n in range(0,hdr.count,PROCESS_CHUNK_SIZE):\n",
    "            with laspy.file.File(fn) as lasfile2:\n",
    "                data = np.vstack((lasfile2.X[n:n+PROCESS_CHUNK_SIZE],\n",
    "                                  lasfile2.Y[n:n+PROCESS_CHUNK_SIZE],\n",
    "                                  lasfile2.Z[n:n+PROCESS_CHUNK_SIZE]))\n",
    "                process_chunk(data,bins,hdr)\n",
    "                processed += lasfile2.X[n:n+PROCESS_CHUNK_SIZE].size\n",
    "            print('processed',processed,'points in ',t.elapsed)\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True, True, True]\n",
      "processed 10000000 points in  16.443815290871328\n",
      "processed 16864177 points in  31.81358622355458\n"
     ]
    }
   ],
   "source": [
    "PROCESS_CHUNK_SIZE = int(1e7)\n",
    "with Timer() as t:\n",
    "    p = Path(LAS_DIRECTORY)\n",
    "    processed = 0\n",
    "    for fn in p.glob('*.las'):\n",
    "        processed += process_file(fn.__str__(),t,processed)\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['324242244607', '324242264656', '324242600663', '324242602472', '324242606025', '324242606476', '324242620412', '324242622252', '324242624076', '324242626061', '324242626661', '324242642056', '324242642527', '324242644661', '324242646403', '324242660017', '324242660576', '324242662434', '324242664146', '324242664601', '324242666256', '324246200276', '324246202261', '324246204234', '324246220102', '324246220636', '324246222414', '324246224210', '324260044454', '324260400205', '324260402001', '324260404041', '324260404647', '324260440014', '324260440616', '324260442472', '324260444455', '324260446423', '324264000245', '324264002012', '324264004043']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "only_digits = re.compile(r\"\\D\")\n",
    "\n",
    "p = Path(OUTPUT_DIR,'r')\n",
    "addresses = [only_digits.sub(\"\",paths.parts[-1]) for paths in p.glob('**/r*.bin')]\n",
    "print(addresses[::100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert tree to tree\n",
    "tree = {}\n",
    "for a in addresses:\n",
    "    t = tree\n",
    "    for s in a:\n",
    "        if s not in t:\n",
    "            t[s] = {} \n",
    "        t = t[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(json.dumps(tree,sort_keys=True, indent=2, separators=(',', ': ')))\n",
    "# convert to list of all possible tiles, and their children\n",
    "\n",
    "def nodes_to_list(prefix, key, value):\n",
    "    hrc = [{'address':prefix+key,\n",
    "            'children': tuple(value.keys())}, \n",
    "          ]\n",
    "    \n",
    "    [hrc.extend(nodes_to_list(prefix+key,k,v)) for k, v in value.items()]\n",
    "    \n",
    "    return hrc\n",
    "\n",
    "hrc = nodes_to_list('','',tree)\n",
    "hrc.sort(key=lambda k: (len(k['address']), k['address']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'address': '',\n",
      " 'children': ('3',),\n",
      " 'mask': 8,\n",
      " 'parentPath': WindowsPath('D:/pointclouds/potree/data/r/r.bin'),\n",
      " 'path': WindowsPath('D:/pointclouds/potree/data/r/r.bin')}\n",
      "{'address': '324264006251',\n",
      " 'children': (),\n",
      " 'mask': 0,\n",
      " 'parentPath': WindowsPath('D:/pointclouds/potree/data/r/32426/40062/r32426400625.bin'),\n",
      " 'path': WindowsPath('D:/pointclouds/potree/data/r/32426/40062/r324264006251.bin')}\n"
     ]
    }
   ],
   "source": [
    "for item in hrc:\n",
    "    path = address_to_path(item['address'])\n",
    "    item.update(\n",
    "        {\n",
    "            'mask': sum([2 ** int(c) for c in item['children']]),\n",
    "            'path': path,\n",
    "            'parentPath': address_to_path(item['address'][:-1])\n",
    "        })\n",
    "    \n",
    "pprint(hrc[0])\n",
    "pprint(hrc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dt = np.dtype([('x','<u4'),('y','<u4'),('z','<u4')])\n",
    "def read_file_at_address(address):\n",
    "    with address_to_path(address).open('r') as f:\n",
    "        points = np.fromfile(f,dtype=dt)\n",
    "    x0, y0, z0 = address_2_origin(address)\n",
    "    points['x'] += x0\n",
    "    points['y'] += y0\n",
    "    points['z'] += z0\n",
    "    return(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def thin_points(points,level):\n",
    "    \"\"\" thin the data in a file\n",
    "    bin the data in 3d cubes, and keep only one point per level\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.DataFrame(points)\n",
    "    n_bins = 256\n",
    "    size = SMALLEST_TILE_SIZE * 2 ** (LEVELS - level) / SCALE\n",
    "    bins = np.linspace(0,size,n_bins+1)\n",
    "    binned = copy.copy(points)\n",
    "    for dim in ['x','y','z']:\n",
    "        df['bin_'+dim] = np.digitize(points[dim],bins) \n",
    "    df.drop_duplicates(inplace=True,subset=('bin_x','bin_y','bin_z'))\n",
    "    subset = df.as_matrix(columns=('x','y','z'))\n",
    "    return(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# loop over all files in tree\n",
    "for h in hrc[::-1]:\n",
    "    # if file doesn't exist, generate it from it's children\n",
    "    if not h['path'].exists():\n",
    "        points = np.hstack([read_file_at_address(h['address']+child) for child in h['children']])\n",
    "        \n",
    "        x0, y0, z0 = address_2_origin(h['address'])\n",
    "        points['x'] -= x0\n",
    "        points['y'] -= y0\n",
    "        points['z'] -= z0\n",
    "        subset = thin_points(points,len(h['address']))\n",
    "        with h['path'].open('w') as f:\n",
    "            subset.tofile(f)\n",
    "        \n",
    "    h['n_points'] = int(h['path'].stat().st_size / dt.itemsize)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hrc_dtype = np.dtype([\n",
    "    (\"mask\", \"<u1\"),            \n",
    "    (\"n_points\", \"<u4\"),   \n",
    "    ])\n",
    "\n",
    "import re\n",
    "only_digits = re.compile(r\"\\D\")\n",
    "output_dir = Path(OUTPUT_DIR,'r').__str__()\n",
    "\n",
    "for d in set(h['path'].parent for h in hrc):\n",
    "    hrc_data = np.array(\n",
    "        [(h['mask'],h['n_points']) for h in hrc if \n",
    "         h['parentPath'].parent == d or h['path'].parent == d],\n",
    "        dtype=hrc_dtype)\n",
    "    path = d.joinpath('r' + only_digits.sub(\"\",d.__str__().replace(output_dir,'')) + '.hrc')\n",
    "    with path.open('w') as f:\n",
    "        hrc_data.tofile(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"boundingBox\": {\n",
      "    \"lx\": 74660,\n",
      "    \"ly\": 351644,\n",
      "    \"lz\": -51250,\n",
      "    \"ux\": 177060,\n",
      "    \"uy\": 454044,\n",
      "    \"uz\": 51150\n",
      "  },\n",
      "  \"hierarchyStepSize\": 5,\n",
      "  \"octreeDir\": \"data\",\n",
      "  \"pointAttributes\": [\n",
      "    \"POSITION_CARTESIAN\"\n",
      "  ],\n",
      "  \"scale\": 0.01,\n",
      "  \"spacing\": 0.01,\n",
      "  \"tightBoundingBox\": {\n",
      "    \"lx\": 91390.24,\n",
      "    \"ly\": 437388.64,\n",
      "    \"lz\": -19.81,\n",
      "    \"ux\": 92514.15000000001,\n",
      "    \"uy\": 438354.63,\n",
      "    \"uz\": 161.28\n",
      "  },\n",
      "  \"version\": \"1.6\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "options = {\n",
    "    \"version\": \"1.6\",\n",
    "    \"octreeDir\": OUTPUT_DIR.parts[-1],\n",
    "    \"boundingBox\": {\n",
    "        \"lx\": int(BBOX['x'][0]),\n",
    "        \"ly\": int(BBOX['y'][0]),\n",
    "        \"lz\": int(BBOX['z'][0]),\n",
    "        \"ux\": int(BBOX['x'][1]),\n",
    "        \"uy\": int(BBOX['y'][1]),\n",
    "        \"uz\": int(BBOX['z'][1])\n",
    "    },\n",
    "    \"tightBoundingBox\": {\n",
    "        \"lx\": bounds[1,0],\n",
    "        \"ly\": bounds[1,1],\n",
    "        \"lz\": bounds[1,2],\n",
    "        \"ux\": bounds[0,0],\n",
    "        \"uy\": bounds[0,1],\n",
    "        \"uz\": bounds[0,2]\n",
    "    },\n",
    "    \"pointAttributes\": [\"POSITION_CARTESIAN\"],\n",
    "    \"spacing\": 0.01,\n",
    "    \"scale\": SCALE,\n",
    "    \"hierarchyStepSize\": HIERACHY_STEP_SIZE,\n",
    "}\n",
    "print(json.dumps(options,sort_keys=True, indent=2, separators=(',', ': ')))\n",
    "\n",
    "with OUTPUT_DIR.parent.joinpath('cloud.js').open('w') as f:\n",
    "    json.dump(options,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OUTPUT_DIR.parts[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
