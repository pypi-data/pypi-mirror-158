{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44f4e641-170d-4fbd-b5af-9e4afd8f5926",
   "metadata": {},
   "source": [
    "# Batching multiple event frames\n",
    "To decrease the time our GPU waits for new data and sits idle, we'll increase the batch size next. Event recordings all have different length, even if it's just microseconds that they are off. In a mini-batch, all the tensors must have the same size. That is why we'll make use of a helper __collate__ function that pads tensors with zeros so that all the (transformed) recordings in the batch have the same shape. You will need to use the ToFrame transform for this to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b28481e-76b6-4dac-b60b-e080ce02cb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://uc3899e340200bcdf953174a3f56.dl.dropboxusercontent.com/zip_download_get/A70VaJ475Xi8ENRCFTlZiqRdmaUcJICmXGjWuMaEUwbJjYV3cy1nsSNsfZn8jKHyEFMo6x3IuOdywOWJqTX8C7SFYndSivEQIprRHn-X86LhfA?dl=1 to ./data/NMNIST/nmnist-archive.zip\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6d15079cbf741788d36ab0c6d1d46e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1181572961 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/NMNIST/nmnist-archive.zip to ./data/NMNIST\n"
     ]
    }
   ],
   "source": [
    "import tonic\n",
    "import tonic.transforms as transforms\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "sensor_size = tonic.datasets.NMNIST.sensor_size\n",
    "frame_transform = transforms.ToFrame(sensor_size=sensor_size, time_window=10000)\n",
    "\n",
    "dataset = tonic.datasets.NMNIST(save_to='./data', train=False, transform=frame_transform)\n",
    "\n",
    "dataloader_batched = DataLoader(dataset, \n",
    "                                shuffle=True, \n",
    "                                batch_size=10, \n",
    "                                collate_fn=tonic.collation.PadTensors(batch_first=False))\n",
    "\n",
    "events, targets = next(iter(dataloader_batched))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584422a4-bea3-4556-9618-0871feef7b73",
   "metadata": {},
   "source": [
    "By default, the resulting tensor will be in the format (Time, batch, channel, height, width) as in [PyTorch RNN](https://pytorch.org/docs/stable/generated/torch.nn.RNN.html?highlight=rnn#torch.nn.RNN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b4481f4-2153-479b-8d69-26cf2e8e7d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 10, 2, 34, 34])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7041827-7710-4633-9b95-2f765ea4fa38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 4, 0, 3, 5, 0, 4, 7, 2, 4])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd80c8c-e784-475a-b76a-8d79579eb4c1",
   "metadata": {},
   "source": [
    "We can set `batch_first=True` in our collate class to change this behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8ad837e-0c31-4782-9306-7b03d12299c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_batched = DataLoader(dataset, \n",
    "                                shuffle=True, \n",
    "                                batch_size=10, \n",
    "                                collate_fn=tonic.collation.PadTensors(batch_first=True))\n",
    "\n",
    "events, targets = next(iter(dataloader_batched))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3cde665-85fa-44cd-b9fd-0835e370fe6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 31, 2, 34, 34])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60361fbe-dad0-466c-a008-05c15e5a6a65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
