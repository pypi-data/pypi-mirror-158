{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d3cfc7a-a8a6-4620-ab0d-d8ed6fa865f6",
   "metadata": {},
   "source": [
    "# Dataset slicing\n",
    "An event recording is somewhat similar to a video. Sometimes it is desirable to slice a single event recording into multiple samples. During training time, we might want to load just a slice of a recording rather than the whole one. This is typically the case when training an ANN on event frames, if one recording contains multiple labels or if recordings are just very long. We specify a `slicer` method which decides how recordings are cut into smaller chunks. Let's look at how we can cut a sample of the N-MNIST dataset which is around 300 ms into smaller pieces of 50 ms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10d81683-553d-49cd-bb7f-a8f6c9cae9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read metadata from disk.\n"
     ]
    }
   ],
   "source": [
    "import tonic\n",
    "from tonic import SlicedDataset\n",
    "from tonic.slicers import SliceByTime\n",
    "\n",
    "dataset = tonic.datasets.NMNIST(save_to='./data', train=False)\n",
    "\n",
    "slicing_time_window = 50000 # microseconds\n",
    "slicer = SliceByTime(time_window=slicing_time_window)\n",
    "sliced_dataset = SlicedDataset(dataset, slicer=slicer, metadata_path='./metadata/nmnist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4250d0c3-9906-4ccb-b42b-dd467e39200c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Went from 10000 samples in the original dataset to 59718 in the sliced version.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Went from {len(dataset)} samples in the original dataset to {len(sliced_dataset)} in the sliced version.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aebec5a2-72ad-405c-9452-b3474729e9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "events, targets = sliced_dataset[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88c85ed-4d8e-4bc4-bdca-ff838cc56a41",
   "metadata": {},
   "source": [
    "We can verify that the difference between last and first timestamp in the slice is not greater than our slicing time window earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f112e009-9abe-4bf9-a01d-f1890b636b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference between last and first timestamp in slice: 49963 us\n"
     ]
    }
   ],
   "source": [
    "slice_time_difference = events[\"t\"][-1] - events[\"t\"][0]\n",
    "print(f\"Difference between last and first timestamp in slice: {slice_time_difference} us\")\n",
    "assert slice_time_difference <= slicing_time_window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212b8345-3756-41b1-91ea-302e3159043b",
   "metadata": {},
   "source": [
    "## Applying transforms post-slicing\n",
    "As normally, we can specify transform and/or target_transform which will be applied to the slice after loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b28837de-3f38-47d9-bb89-bbf37273c66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read metadata from disk.\n"
     ]
    }
   ],
   "source": [
    "frame_transform = tonic.transforms.ToImage(sensor_size=tonic.datasets.NMNIST.sensor_size)\n",
    "\n",
    "sliced_dataset = SlicedDataset(dataset, slicer=slicer, transform=frame_transform, metadata_path='./metadata/nmnist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "488c1135-5928-4ee1-a7b4-19eb4e89a115",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames, targets = sliced_dataset[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211ea6d8-f9c3-4a3f-923b-a97114a2e31f",
   "metadata": {},
   "source": [
    "We can verify that the sum of events in the frames is the same as the number of events without transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdece00a-de7b-4572-b879-aa3c166c6577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of spikes: 317\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of spikes: \" + str(frames.sum()))\n",
    "assert frames.sum() == len(events)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0fdeb4-8788-40ff-9e81-7c1dec267899",
   "metadata": {},
   "source": [
    "## Caching a SlicedDataset\n",
    "Additionally, we can wrap our newly sliced dataset in a `MemoryCachedDataset`, which will write the slices to working memory. We'll also provide an augmentation transform that is applied post-loading from cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9c358dd-a2f9-4325-9da9-c0fdb4f26f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from tonic import MemoryCachedDataset\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "augmentation = tonic.transforms.Compose([torch.tensor,\n",
    "                                         torchvision.transforms.RandomRotation([-45,45])])\n",
    "augmented_dataset = MemoryCachedDataset(sliced_dataset, transform=augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1096bdc-a8f9-4847-bc0d-81f65c9f6520",
   "metadata": {},
   "outputs": [],
   "source": [
    "rotated_frames, targets = augmented_dataset[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d8a3ccd-9ad4-46cc-999f-8314b941490b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fbbb0082bd0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(rotated_frames[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64d913b-a784-4abe-bd97-51f1d0bc1d3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
