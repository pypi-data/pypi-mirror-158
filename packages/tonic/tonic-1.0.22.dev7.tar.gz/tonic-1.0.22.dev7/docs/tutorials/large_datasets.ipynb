{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccd63c76-ef17-4afd-b6ce-e839c123b086",
   "metadata": {},
   "source": [
    "# Working with larger datasets and multiple data\n",
    "Some datasets contain GB of multiple data types and targets. In this tutorial we are going to look at how we can slice different data types at the same time in long recordings  into smaller chunks and how we can cache those slices to disk for efficient loading. As an example we are going to work with the DAVIS dataset. It's convenient since we can pick and download single recordings of a few hundred MB in size for the purpose of this tutorial but the lessons learned will scale to larger datasets as well. One recording contains a tuple of data for (events, imu, images). Let's start by downloading it. This tutorial also works with the Visual Place Recognition dataset (VPR), but be aware that it's much larger at ~74 GB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b497641-bbd6-45b1-af91-8c85729c640d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tonic\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4dc5b07-4144-405d-9538-b07dd00849cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://download.ifi.uzh.ch/rpg/web/datasets/davis/shapes_6dof.bag to ./data/DAVISDATA/shapes_6dof.bag\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a074be0ab0494d36a82fa23115ab14b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/321575849 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://download.ifi.uzh.ch/rpg/web/datasets/davis/shapes_rotation.bag to ./data/DAVISDATA/shapes_rotation.bag\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd7ca10d150f4fd28c3e663dc8afed10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/388784308 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.24 s, sys: 2.83 s, total: 11.1 s\n",
      "Wall time: 1min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# first time we want to access this dataset the download is triggered\n",
    "dataset = tonic.datasets.DAVISDATA(save_to='./data', recording=['shapes_6dof', 'shapes_rotation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9791e0-973c-432b-872a-42b03b29df6f",
   "metadata": {},
   "source": [
    "The data is now on our harddrive. Next time we re-run our script, this method will return much quicker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db7ec27c-e909-4c89-a7e8-8ef64930ecdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 543 µs, sys: 113 µs, total: 656 µs\n",
      "Wall time: 441 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# second time we want to access this dataset some lightweight file checks return quickly\n",
    "dataset = tonic.datasets.DAVISDATA(save_to='./data', recording=['shapes_6dof', 'shapes_rotation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a669a499-2a82-4fcb-a0eb-3671a4a8fdab",
   "metadata": {},
   "source": [
    "Not only do we want to slice the events for this recording, we also want to slice imu and image data at the same time steps. For that we'll have to write a custom slicing method which implements the tonic.slicers.Slicer protocol. That means that we need to implement at least `get_slice_metadata` and `slice_with_metadata` without having to subclass it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d07b9457-8bd8-4ded-b959-e2afa26b378c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tonic.slicers import SliceByTime\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, List, Tuple\n",
    "\n",
    "@dataclass\n",
    "class MultiDataSlicer:\n",
    "    time_window: float\n",
    "    overlap: float = 0.0\n",
    "    include_incomplete: bool = False\n",
    "\n",
    "    # this method receives all the data for one recording/sample. Based on the timestamps in there, \n",
    "    # we'll work out the boundaries of slices, in this case according to a time window. This method\n",
    "    # is called once per sample.\n",
    "    def get_slice_metadata(self, data):\n",
    "        events, imu, images = data\n",
    "        min_ts = min(min(events[\"t\"]), min(imu[\"ts\"]), min(images[\"ts\"]))\n",
    "        max_ts = max(max(events[\"t\"]), max(imu[\"ts\"]), max(images[\"ts\"]))\n",
    "        stride = self.time_window - self.overlap\n",
    "        if self.include_incomplete:\n",
    "            n_slices = int(np.ceil(((max_ts - min_ts) - self.time_window) / stride) + 1)\n",
    "        else:\n",
    "            n_slices = int(np.floor(((max_ts - min_ts) - self.time_window) / stride) + 1)\n",
    "        window_start_times = np.arange(n_slices) * stride + min_ts\n",
    "        window_end_times = window_start_times + self.time_window\n",
    "        return list(zip(window_start_times, window_end_times))\n",
    "\n",
    "    # Even if we are only interested in a single slice, the data is still stored in a file for the\n",
    "    # whole recording. To access that slice, we thus need to load the whole recording and then pick\n",
    "    # the part of it that we are interested in. This method receives the whole data recording and \n",
    "    # metadata about where a slice starts and stops. This can be timestamps, indices or other things.\n",
    "    @staticmethod\n",
    "    def slice_with_metadata(data: Tuple[Any], metadata: List[Tuple[int, int]]):\n",
    "        events, imu, images = data # this is data for a whole recording\n",
    "        start, stop = metadata[0][0], metadata[0][1]\n",
    "        event_slice = events[np.logical_and(events[\"t\"]>=start, events[\"t\"]<stop)]\n",
    "        imu_slice = {}\n",
    "        imu_slice[\"ts\"] = imu[\"ts\"][np.logical_and(imu[\"ts\"]>=start, imu[\"ts\"]<stop)]\n",
    "        imu_slice[\"rotQ\"] = imu[\"rotQ\"][np.logical_and(imu[\"ts\"]>=start, imu[\"ts\"]<stop)]\n",
    "        imu_slice[\"angV\"] = imu[\"angV\"][np.logical_and(imu[\"ts\"]>=start, imu[\"ts\"]<stop)]\n",
    "        imu_slice[\"acc\"] = imu[\"acc\"][np.logical_and(imu[\"ts\"]>=start, imu[\"ts\"]<stop)]\n",
    "        imu_slice[\"mag\"] = imu[\"mag\"][np.logical_and(imu[\"ts\"]>=start, imu[\"ts\"]<stop)]\n",
    "        image_slice = {}\n",
    "        image_slice[\"ts\"] = images[\"ts\"][np.logical_and(images[\"ts\"]>=start, images[\"ts\"]<stop)]\n",
    "        image_slice[\"frames\"] = images[\"frames\"][np.logical_and(images[\"ts\"]>=start, images[\"ts\"]<stop)]\n",
    "        return (event_slice, imu_slice, image_slice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391ecea9-e457-467b-9e3a-ec9516c80e39",
   "metadata": {},
   "source": [
    "Now that we specified how our recording should be chunked, we'll wrap our dataset in a SlicedDataset class, where we pass our MultiDataSlicer object. To showcase a common use case, we'll also specify a ToFrame transform which will be applied to every slice after loading it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ff3c1de-88da-4bf9-9e0b-621bc5e541c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tonic import SlicedDataset\n",
    "import tonic.transforms as transforms\n",
    "\n",
    "# the time length of one slice of recording\n",
    "slicing_time_window = 200000\n",
    "slicer = MultiDataSlicer(time_window=slicing_time_window)\n",
    "\n",
    "# bin events in a slice to frames \n",
    "frame_transform = transforms.ToFrame(sensor_size=dataset.sensor_size, time_window=2000)\n",
    "\n",
    "def custom_transform(data):\n",
    "    events, imu, images = data\n",
    "    return (frame_transform(events), imu, images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de2e98b-4a99-419f-84f8-09b0ebd6f8e0",
   "metadata": {},
   "source": [
    "Because it is quite expensive to compute the metadata for a large dataset, we'll also provide a path where it is stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3fa92dc3-e39e-4512-b317-36427472cc0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5d7c617-c0ed-49ad-a0c4-294246567de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata written to disk.\n",
      "CPU times: user 8.38 s, sys: 482 ms, total: 8.86 s\n",
      "Wall time: 8.86 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sliced_dataset = SlicedDataset(dataset, slicer=slicer, transform=custom_transform, metadata_path='./metadata/large_datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56284f91-4525-4d55-8fb0-939eb15f9acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cut a dataset of 2 recording into 596 slices.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Cut a dataset of {len(dataset)} recording into {len(sliced_dataset)} slices.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c5acca-b129-4f6c-ae55-cf2f620790d3",
   "metadata": {},
   "source": [
    "The next time we instantiate this SlicedDataset, we'll just load it from disk for a considerable speed up of accessing slicing metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71cabd24-c65b-47d1-9801-c689c4073861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read metadata from disk.\n",
      "CPU times: user 1.44 ms, sys: 233 µs, total: 1.67 ms\n",
      "Wall time: 1.39 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sliced_dataset = SlicedDataset(dataset, slicer=slicer, transform=custom_transform, metadata_path='./metadata/large_datasets')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff3c473-be24-487f-9d0e-8b90ead8390c",
   "metadata": {},
   "source": [
    "In a last step, we are going to make use of caching. This is important to avoid loading the whole recording whenever we want to load a slice. When we wrap our sliced dataset in a CachedDataset, we write the data for one slice to disk. Next time want that same slice, we can just load it from disk, where it sits in an efficient format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d55a7c3f-d421-4937-8042-90eec17b5065",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tonic import SlicedDataset, CachedDataset\n",
    "\n",
    "cached_dataset = CachedDataset(sliced_dataset, cache_path='./cache/large_datasets')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e873092-984e-4de5-973a-19c9769c5128",
   "metadata": {},
   "source": [
    "The first time we access a sliced sample, under the hood Tonic loads the whole recording, slices it according to metadata, applies transforms and eventually writes it to a cache directory before returning the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "69d2ac0e-2fa6-4ac0-ac52-9f0da3451b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.74 s, sys: 247 ms, total: 1.99 s\n",
      "Wall time: 1.99 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# first time access\n",
    "(event_frames, imu, images), targets = cached_dataset[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfefae0b-4657-4cc4-86b8-e91bd4f6a7dd",
   "metadata": {},
   "source": [
    "Let's verify that the data looks alright:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f77f38b-4e2a-40ed-9a13-57f7789f1b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event frames have a shape of (99, 2, 180, 240),\n",
      "images for this slice have a shape of (5, 180, 240) and go from 220326 to 396587 microseconds\n",
      "and imu time stamps range from 200301 to 399602 microseconds.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Event frames have a shape of {event_frames.shape},\\nimages for this slice have a shape of {images['frames'].shape} and go from {images['ts'][0]} to {images['ts'][-1]} microseconds\\nand imu time stamps range from {imu['ts'][0]} to {imu['ts'][-1]} microseconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b8771c-61c9-4f0b-ac0e-1a07ee88e875",
   "metadata": {},
   "source": [
    "Next time we access this particular sample, it will be faster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31f522b0-4576-4e80-8711-f78ea59056c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 146 ms, sys: 0 ns, total: 146 ms\n",
      "Wall time: 146 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# second time access\n",
    "(event_frames, imu, images), targets = cached_dataset[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544ac69a-1205-4870-8ce4-2275f11c25bc",
   "metadata": {},
   "source": [
    "Last but not least we also check the disk footprint of a single slice in cache. During caching, we make use of lightweight lzf compression, which can save a lot of space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1889d7e6-5aec-4c05-ad50-34b065883a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last slice takes 1.885819 MB on disk.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "print(f\"Last slice takes {sum(p.stat().st_size for p in Path('./cache/large_datasets').rglob('*'))/1e6} MB on disk.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc88605-6148-434c-a311-d10f64c1c507",
   "metadata": {},
   "source": [
    "That's pretty good for some 100 images, plus imu and gps data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
