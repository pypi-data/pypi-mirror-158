{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0752c108",
   "metadata": {},
   "source": [
    "# Reading/Writing a ðŸŒˆ\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe321e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chromatic import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebeb44a9",
   "metadata": {},
   "source": [
    "## Reading Files\n",
    "\n",
    "One key goal of `chromatic` is to make it easy to load spectroscopic light curves from a variety of different file formats, so that the outputs from multiple different pipelines can be standardized into objects that can be direcly compared to one another. We hope to provide an straightforward way to check one analysis vs another as quickly as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d094d7",
   "metadata": {},
   "source": [
    "### Download Example Inputs\n",
    "\n",
    "If you want to test out any of these readers, you'll need data files in each format to test on. You can download *some* example datasets from [this link](https://www.dropbox.com/s/es5drnp6ufkz8wv/example-datasets.zip?dl=0). Simply extract that `.zip` file into the directory from which you'll be running this notebook. Another source of files you might want to try reading would be the simulated data generated for the [ers-transit Spring 2022 Data Challenge](https://ers-transit.github.io/data-challenge-with-simulated-data.html#simulated-data)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9f9647",
   "metadata": {},
   "source": [
    "### `chromatic` rainbow files (`*.rainbow.npy`)\n",
    "\n",
    "The `chromatic` toolkit saves files in its own default format, which can then be shared and loaded back in. These files directly encode the core dictionaries in binary files, so they load and save quickly. They have the extension `.rainbow.npy`. These files can be written from any `Rainbow` object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0afc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = Rainbow(\"example-datasets/chromatic/test.rainbow.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c54f89",
   "metadata": {},
   "source": [
    "The `Rainbow` reader will try to guess the format of the file from the filepath. If that doesn't work for some reason, in this case you can feed in the keyword `format='rainbow_npy'`, to require the use of the `from_rainbow_npy` reader needed for these files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4672fa80",
   "metadata": {},
   "source": [
    "### `chromatic` rainbow FITS files (`*.rainbow.fits`)\n",
    "\n",
    "Because you might want to share a `Rainbow` object with someone not using Python, we define a FITS-based file format. The [Flexible Image Transport System](https://docs.astropy.org/en/stable/io/fits/index.html) is pretty common in astronomy, so there's a good chance someone will be able to load this file into whatever coding language they're using. These files have the extension `.rainbow.fits`, and they will load a tiny bit more slowly than `.rainbow.npy` files. These files can be written from any `Rainbow` object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b3edfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = Rainbow(\"example-datasets/chromatic/test.rainbow.fits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dfeab8",
   "metadata": {},
   "source": [
    "The `Rainbow` reader will try to guess the format of the file from the filepath. If that doesn't work for some reason, in this case you can feed in the keyword `format='rainbow_FITS'`, to require the use of the `from_rainbow_FITS` reader needed for these files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e116a8c",
   "metadata": {},
   "source": [
    "### generic text files (`*.txt`, `*.csv`)\n",
    "\n",
    "Text files are slower to read or write, but everyone can make them! This reader will try to load one giant text file in which light curves for all wavelengths are stacked on top of each other or spectra for all times are stacked on top of each other. The text file should at least have columns that look like:\n",
    "- `wavelength` for wavelength in microns\n",
    "- `time` for time in days (preferably BJD$_{\\rm TDB}$)\n",
    "- `flux` for flux in any units\n",
    "- `uncertainty` for flux uncertainties in the same units as `flux`\n",
    "Additional columns will also be read, and they will be stored in the `.fluxlike` core dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee520625",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = Rainbow(\"example-datasets/chromatic/test.rainbow.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f1f612",
   "metadata": {},
   "source": [
    "If the file-format guess fails, you can feed in the keyword `format='text'` to tell the reader to expect one of these files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d37fee1",
   "metadata": {},
   "source": [
    "### STScI `jwst` pipeline outputs (`x1dints.fits`)\n",
    "\n",
    "The `jwst` pipeline developed at the Space Telescope Science Institute will produce extract 1D stellar spectra for time-series observations with the James Webb Space Telescope. Details about the pipeline itself are available [here](https://jwst-pipeline.readthedocs.io/en/latest/). \n",
    "\n",
    "These files typically end with the `_x1dints.fits` suffix. Each file contains a number of individual \"integrations\" (= time points). Because the datasets can get large, sometimes a particular observation might be split into multiple segments, each with its own file. As such, the reader for these files is designed to handle either a single file or a path with a `*` in it that points to a group of files from an observation that's been split into segments.\n",
    "\n",
    "This reader has been tested on all of the `x1dints` files produced as Stage 2 Data Products in the simulated datasets available [here](https://app.box.com/folder/154382715453?s=tj1jnivn9ekiyhecl5up7mkg8xrd1htl)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea888d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = Rainbow(\"example-datasets/stsci/*_x1dints.fits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b24008",
   "metadata": {},
   "source": [
    "If the file-format guess fails, you can feed in the keyword `format='x1dints'` to tell the reader to expect one of these files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a486185",
   "metadata": {},
   "source": [
    "### `eureka` pipeline outputs (`S3_*_Table_Save.txt`)\n",
    "\n",
    "The `eureka` pipeline is one of many community tools being designed to extract spectra from JWST data. Details about the pipeline itself are available [here](https://github.com/kevin218/Eureka). \n",
    "\n",
    "These files typically have names that look something like `S3_*_Table_Save.txt`, and they contain fluxes as a function of wavelength and time, stored as an astropy `ecsv` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a576d847",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = Rainbow(\"example-datasets/eureka/S3_wasp43b_Table_Save.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f23bf80",
   "metadata": {},
   "source": [
    "If the file-format guess fails, you can feed in the keyword `format='eureka'` to tell the reader to expect one of these files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248fb6c9",
   "metadata": {},
   "source": [
    "### other file formats\n",
    "\n",
    "At the [ers-transit Spring 2022 Data Challenge](https://ers-transit.github.io/data-challenge-with-simulated-data.html), lots of folks submitted time-series spectra in a variety of different formats. We added some readers to load those submissions, and for convenience we include those readers in the current distribution of `chromatic`. Here is a complete list of available file formats:\n",
    "\n",
    "- `format='coulombe'`\n",
    "- `format='dossantos'`\n",
    "- `format='eureka'`\n",
    "- `format='espinoza'`\n",
    "- `format='feinstein'`\n",
    "- `format='radica'`\n",
    "- `format='rainbow_FITS'`\n",
    "- `format='rainbow_npy'`\n",
    "- `format='schlawin'`\n",
    "- `format='text'`\n",
    "- `format='x1dints'`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebad51da",
   "metadata": {},
   "source": [
    "## Writing Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11701361",
   "metadata": {},
   "source": [
    "### `chromatic` rainbow files (`*.rainbow.npy`)\n",
    "\n",
    "The default file format for saving files encodes the core dictionaries in binary files, using the extension `.rainbow.npy`. This is a file that can be read directly back into `chromatic`. (Indeed, the commands below created the file that we read above.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8cd686",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated = SimulatedRainbow().inject_noise().inject_transit()\n",
    "simulated.save(\"example-datasets/chromatic/test.rainbow.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62edafe9",
   "metadata": {},
   "source": [
    "### `chromatic` rainbow FITS files (`*.rainbow.fits`)\n",
    "\n",
    "If you want to share your Rainbow object with someone who might not be using Python, consider sharing a `.rainbow.fits` file. This is a normal FITS file that many astronomers will have a way of reading. The primary extension has no data but a header that might contain some metadata. The three other extensions `fluxlike`, `wavelike`, and `timelike` contain quantities that have shapes of `(nwave, ntime)`, `(nwave)`, `(ntime)`, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea58b487",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated.save(\"example-datasets/chromatic/test.rainbow.fits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0837eac",
   "metadata": {},
   "source": [
    "### generic text files (`*.txt`, `*.csv`)\n",
    "\n",
    "Text files provide a more generally readable file format, even though they may be slower to read or write. This writer will create one giant text file that stacks the light curves for all wavelengths on top of each other (if the `group_by='wavelength'` keyword is set) or the spectra for all times on top of each other (if the `group_by='time'` keyword is set). The resulting text file should at least have columns that look like:\n",
    "- `wavelength` for wavelength in microns\n",
    "- `time` for time in days (preferably BJD$_{\\rm TDB}$)\n",
    "- `flux` for flux in any units\n",
    "- `uncertainty` for flux uncertainties in the same units as `flux`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1940fedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated.save(\"example-datasets/chromatic/test.rainbow.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ee8df0",
   "metadata": {},
   "source": [
    "## Create Your Own!\n",
    "Naturally, you might want to add new readers to make use of the outputs from other pipelines or new writers to feed into various light curve analyses. See [Designing New ðŸŒˆ Features ](../designing) to learn how!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
