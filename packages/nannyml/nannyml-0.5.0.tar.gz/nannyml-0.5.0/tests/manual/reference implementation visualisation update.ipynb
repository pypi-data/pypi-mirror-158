{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a58f2e02",
   "metadata": {},
   "source": [
    "Done\n",
    "- created step plot functionality\n",
    "- created artificial endpoint generation\n",
    "- seperated legend label aruguments form hover label arguments\n",
    "- improved legend generation\n",
    "- added incomplete target functionality\n",
    "- created reference implementation for: (1) target distribution monitoring (2) realised performance monitoring (3) correct naming of plotting elements \n",
    "\n",
    "Todo\n",
    "- ordered function arguments by importance and added typing information\n",
    "- cleaned up the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379cab7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add incomplete target data functionality\n",
    "# clean up all arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dd6f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf38b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nannyml as nml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7b0b88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nannyml.plots._step_plot import _step_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52670c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference, analysis, analysis_target = nml.load_synthetic_binary_classification_dataset()\n",
    "chunk_size = 5000\n",
    "reference_and_analysis = pd.concat([reference, analysis], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df13c412",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = nml.extract_metadata(data = reference, model_name='wfh_predictor')\n",
    "metadata.target_column_name = 'work_home_actual'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bcc524",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK_KEY_COLUMN_NAME = 'key'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf8134d",
   "metadata": {},
   "source": [
    "# Confidence based performance estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc816d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = nml.CBPE(model_metadata=metadata, chunk_size=chunk_size)\n",
    "estimator.fit(reference)\n",
    "estimated_performance = estimator.estimate(data=reference_and_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613c8682",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimation_results = estimated_performance.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e25e7e",
   "metadata": {},
   "source": [
    "still a bug here, roc_auc in referene period should not be estimated\n",
    "\n",
    "suggestion: add realised_roc_auc column to output ==> thant that column can be combined with the estimated roc_auc_column to create the metric_column and estimated can be set to false in reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79254d59",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "estimation_results['thresholds'] = list(zip(estimation_results.lower_threshold, estimation_results.upper_threshold))\n",
    "\n",
    "estimation_results['estimated'] = True\n",
    "\n",
    "plot_partition_separator = len(estimation_results.value_counts()) > 1\n",
    "\n",
    "fig = _step_plot(\n",
    "    table=estimation_results,\n",
    "    metric_column_name='estimated_roc_auc',\n",
    "    chunk_column_name=CHUNK_KEY_COLUMN_NAME,\n",
    "    drift_column_name='alert',\n",
    "\n",
    "    threshold_column_name='thresholds',\n",
    "    threshold_legend_label='Performance threshold',\n",
    "    title='ROC AUC over time (realised and estimated)',\n",
    "    y_axis_title='ROC AUC',\n",
    "    v_line_separating_analysis_period=plot_partition_separator,\n",
    "    estimated_column_name='estimated',\n",
    "    confidence_column_name='confidence',\n",
    "    hover_labels=['Chunk', 'ROC AUC'],\n",
    "#     hover_marker_labels=['Reference', 'No performance drop', 'Probable performance drop'],\n",
    "    hover_marker_labels=['', '', ''],\n",
    "    chunk_legend_labels=['Reference period (realised performance)', 'Analysis period (estimated performance, using CBPE)'],\n",
    "    confidence_legend_label='Estimated performance confidence band',\n",
    "    drift_legend_label='Probable drop in performance',\n",
    "    \n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db6af89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "# data = pd.DataFrame(\n",
    "#     {'end_date': pd.date_range('2021-01-01', '2021-08-30', freq='M'),\n",
    "#      'chunk_type': ['p1'] * 3 + ['p2'] * 4,\n",
    "#      'metric':np.arange(7)}\n",
    "# )\n",
    "\n",
    "# data.insert(0, 'start_date', data['end_date'] - pd.offsets.MonthBegin())\n",
    "\n",
    "# data['mid_point_date'] = data['start_date'] + (data['end_date'] - data['start_date']) / 2\n",
    "\n",
    "# def _create_artificial_end_point(data):\n",
    "#     data_point_hack = data.tail(1).copy()\n",
    "#     data_point_hack['start_date'] = data_point_hack['end_date']\n",
    "#     data_point_hack['end_date'] = pd.NaT\n",
    "#     data_point_hack['mid_point_date'] = pd.NaT\n",
    "#     data_point_hack.index = data_point_hack.index + 1\n",
    "#     return pd.concat([data, data_point_hack], axis=0)\n",
    "\n",
    "\n",
    "# fig = go.Figure()\n",
    "\n",
    "# colors = ['blue', 'red']\n",
    "# chunk_types = data['chunk_type'].unique()\n",
    "\n",
    "# for i, chunk_type in enumerate(chunk_types):\n",
    "    \n",
    "#     data_subset = create_artificial_end_point(data.loc[(data['chunk_type'] == chunk_type)])\n",
    "    \n",
    "#     display(data_subset)\n",
    "    \n",
    "#     fig.add_trace(\n",
    "#         go.Scatter(\n",
    "#             mode='lines',\n",
    "#             line=dict(shape='hv', color=colors[i]),\n",
    "#             x=data_subset['start_date'],\n",
    "#             y=data_subset['metric'],\n",
    "#             hoverinfo='skip'\n",
    "#         )\n",
    "#     )\n",
    "    \n",
    "#     fig.add_trace(\n",
    "#         go.Scatter(\n",
    "#             mode='markers',\n",
    "#             marker=dict(color=colors[i]),\n",
    "#             x=data_subset['mid_point_date'],\n",
    "#             y=data_subset['metric']\n",
    "#         )\n",
    "#     )\n",
    "    \n",
    "# fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a3b842",
   "metadata": {},
   "source": [
    "# Reconstruction error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3def68",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcerror_calculator = nml.DataReconstructionDriftCalculator(model_metadata=metadata, chunk_size=chunk_size)\n",
    "rcerror_calculator.fit(reference_data=reference)\n",
    "rcerror_results = rcerror_calculator.calculate(data=reference_and_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddaae9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = rcerror_results.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d94ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_partition_separator = len(data.value_counts()) > 1\n",
    "data['thresholds'] = list(zip(data.lower_threshold, data.upper_threshold))\n",
    "fig = _step_plot(\n",
    "    table=data,\n",
    "    metric_column_name='reconstruction_error',\n",
    "    chunk_column_name=CHUNK_KEY_COLUMN_NAME,\n",
    "    drift_column_name='alert',\n",
    "    threshold_column_name='thresholds',\n",
    "    title='Reconstruction error over time',\n",
    "    y_axis_title='Reconstruction error',\n",
    "    v_line_separating_analysis_period=plot_partition_separator,\n",
    "    hover_labels=['Chunk', 'RC Error'],\n",
    "    hover_marker_labels=['', '', '']\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c334cd0d",
   "metadata": {},
   "source": [
    "# Continuous/cartegoric univariate data drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5382410d",
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate_calculator = nml.UnivariateStatisticalDriftCalculator(model_metadata=metadata, chunk_size=chunk_size)\n",
    "univariate_calculator.fit(reference_data=reference)\n",
    "univariate_results = univariate_calculator.calculate(data=reference_and_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9094d88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = univariate_results.data\n",
    "metric_column_name, _, drift_column_name, _ = [c for c in univariate_results.data.columns if c.startswith('tenure')]\n",
    "metric_label = metric_column_name.split('_')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9462f047",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_partition_separator = len(data.value_counts()) > 1\n",
    "\n",
    "fig = _step_plot(\n",
    "    table=data,\n",
    "    metric_column_name=metric_column_name,\n",
    "    chunk_column_name=CHUNK_KEY_COLUMN_NAME,\n",
    "    drift_column_name=drift_column_name,\n",
    "#     threshold_column_name=threshold_column_name,\n",
    "    title='KS D-statistic of {} over time'.format(metric_label),\n",
    "    y_axis_title='D-statistic',\n",
    "    v_line_separating_analysis_period=plot_partition_separator,\n",
    "    statistically_significant_column_name=drift_column_name,\n",
    "    hover_labels=['Chunk', 'D-statistic'],\n",
    "    hover_marker_labels=['', '', '']\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdda3efc",
   "metadata": {},
   "source": [
    "# Realised performance monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e157a7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rperf_results = estimation_results.copy()\n",
    "rperf_results = rperf_results.rename(columns={'estimated_roc_auc':'roc_auc'})\n",
    "rperf_results = rperf_results.drop(columns=['confidence', 'estimated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f05e8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rperf_results['realised_target_percentage'] = 1\n",
    "rperf_results.iloc[-8:, -1] = [0.33] * 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b374a9f",
   "metadata": {},
   "source": [
    "when realised target percange < 0.25, rows should be removed \n",
    "\n",
    "! use with caution, as it assumed incompletion rate is monotonous decreasing from the moment it happens\n",
    "\n",
    "See example in target distribution monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79da6c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_partition_separator = len(estimation_results.value_counts()) > 1\n",
    "\n",
    "fig = _step_plot(\n",
    "    table=rperf_results,\n",
    "    metric_column_name='roc_auc',\n",
    "    chunk_column_name=CHUNK_KEY_COLUMN_NAME,\n",
    "    drift_column_name='alert',\n",
    "    threshold_column_name='thresholds',\n",
    "    threshold_legend_label='Performance threshold',\n",
    "    title='ROC AUC over time (realised)',\n",
    "    y_axis_title='ROC AUC',\n",
    "    v_line_separating_analysis_period=plot_partition_separator,\n",
    "    hover_labels=['Chunk', 'ROC AUC', 'Target data'],\n",
    "#     hover_marker_labels=['Reference', 'No performance change', 'Performance change'],\n",
    "    hover_marker_labels=['', '', ''],\n",
    "    drift_legend_label='Change in performance',\n",
    "    partial_target_column_name='realised_target_percentage'\n",
    "    \n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57b796e",
   "metadata": {},
   "source": [
    "# Target distribution monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7180f8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdist_results = estimation_results.copy()\n",
    "tdist_results = tdist_results.drop(columns=['confidence', 'estimated'])\n",
    "tdist_results = tdist_results.rename(columns={'estimated_roc_auc':'churn_rate'})\n",
    "tdist_results['churn_rate'] = tdist_results['churn_rate'] - 0.9\n",
    "\n",
    "tdist_results.lower_threshold = tdist_results.lower_threshold - 0.9\n",
    "tdist_results.upper_threshold = tdist_results.upper_threshold - 0.9\n",
    "tdist_results['thresholds'] = list(zip(tdist_results.lower_threshold, tdist_results.upper_threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c250bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdist_results['realised_target_percentage'] = 1\n",
    "tdist_results.iloc[-3:, -1] = [0.75, 0.33, 0.1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479a6808",
   "metadata": {},
   "source": [
    "when realised target percange < 0.25, rows should be removed \n",
    "\n",
    "! use with caution, as it assumed incompletion rate is monotonous decreasing from the mome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d1581b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdist_results = tdist_results.loc[tdist_results['realised_target_percentage'] > 0.25, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b0bcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_partition_separator = len(estimation_results.value_counts()) > 1\n",
    "\n",
    "fig = _step_plot(\n",
    "    table=tdist_results,\n",
    "    metric_column_name='churn_rate',\n",
    "    chunk_column_name=CHUNK_KEY_COLUMN_NAME,\n",
    "    drift_column_name='alert',\n",
    "    statistically_significant_column_name='alert',\n",
    "    drift_legend_label='Target drift',\n",
    "    threshold_column_name='thresholds',\n",
    "    threshold_legend_label='Target threshold',\n",
    "    title='Churn rate over time',\n",
    "    y_axis_title='Churn rate',\n",
    "    v_line_separating_analysis_period=plot_partition_separator,\n",
    "    hover_labels=['Chunk', 'Churn rate', 'Target data'],\n",
    "#     hover_marker_labels=['Reference', 'No target drift', 'Target drift'],\n",
    "    hover_marker_labels=['', '', ''],\n",
    "    partial_target_column_name='realised_target_percentage'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
